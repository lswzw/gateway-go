# Gateway-Go 性能测试报告

## 1. 测试背景

### 测试目标
验证 Gateway-Go 网关在高并发场景下的稳定性和性能表现，评估插件对性能的影响。

### 测试内容
1. 有无插件时并发用户数对网关性能的影响
2. 吞吐量（Requests Per Second, RPS）测试
3. 网关转发性能与直接访问的对比

### 后端服务
- Nginx 简单静态服务，用于模拟实际业务场景
- 服务地址：172.17.0.2
- 内容类型：GET 请求，返回 200 状态码

## 2. 测试环境

### 测试工具
- **Apache JMeter** - 用于压力测试

### 网关配置
- **网关版本**：1.0.0
- **部署方式**：单副本
- **服务类型**：Gateway-Go

### 后端服务
- **服务类型**：Nginx
- **服务地址**：172.17.0.2
- **内容类型**：GET 请求，返回 200 状态码

### 硬件环境
- **测试机配置**：CPU 2核，2GB 内存
- **部署服务**：2个 Nginx（后端服务和认证服务）、网关服务
- **网络环境**：本机网络，延迟低于 1ms

### 内核参数优化
```bash
net.core.somaxconn = 65535
net.core.netdev_max_backlog = 5000
net.ipv4.tcp_max_syn_backlog = 65535
net.ipv4.tcp_fin_timeout = 30
net.ipv4.tcp_keepalive_time = 1200
net.ipv4.tcp_max_tw_buckets = 5000
vm.swappiness = 10
vm.dirty_ratio = 15
vm.dirty_background_ratio = 5
fs.file-max = 1000000
```

## 3. 测试方法

### 测试工具配置

#### 线程组参数
- **并发用户数**：1000、2000、3000、4000
- **发送次数**：30 次

#### HTTP 请求设置
- **请求类型**：GET
- **请求地址**：172.17.0.2
- **断言**：响应状态码 200

#### 监控指标
- 样本数
- 吞吐量（RPS）

## 4. 测试结果

### 4.1 性能指标对比

#### 直接访问（绕过网关）
| 并发用户数 | 样本数 | 吞吐量 (RPS) |
|:----------:|:------:|:------------:|
| 2000       | 60000  | 11037        |
| 3000       | 90000  | 6424         |
| 4000       | 120000 | 3560         |

#### 健康检查接口（网关自身接口）
| 并发用户数 | 样本数 | 吞吐量 (RPS) |
|:----------:|:------:|:------------:|
| 2000       | 60000  | 8819         |
| 3000       | 90000  | 5475         |
| 4000       | 120000 | 4661         |

#### 无插件转发
| 并发用户数 | 样本数 | 吞吐量 (RPS) |
|:----------:|:------:|:------------:|
| 1000       | 30000  | 5525         |
| 1200       | 36000  | 5389         |

#### 走插件转发
| 并发用户数 | 样本数 | 吞吐量 (RPS) |
|:----------:|:------:|:------------:|
| 800        | 24000  | 3460         |

### 4.2 性能对比总结
| 场景 | 并发用户数 | 吞吐量 (RPS) | 吞吐量下降幅度（与直接访问对比） |
|:----:|:----------:|:------------:|:--------------------------------:|
| 直接访问 | 2000 | **11037** | - |
| 健康检查接口 | 2000 | 8819 | **20%** |
| 无插件转发 | 1000 | 5525 | **50%** |
| 走插件转发 | 800 | 3460 | **69%** |

## 5. 压测结果分析

### 5.1 直接访问 vs 健康检查接口

#### 直接访问（绕过网关）
- **性能特点**：
  - 吞吐量随并发用户数增加先升高后下降
  - **2000并发用户**时吞吐量为 **11037 RPS**（峰值）
  - **3000并发用户**时降至 **6424 RPS**
  - **4000并发用户**时进一步下降至 **3560 RPS**

- **性能瓶颈分析**：
  - 测试机资源（2核CPU + 2GB内存）成为瓶颈
  - 当并发用户数超过2000时，硬件资源接近饱和
  - CPU、内存或网络带宽限制导致处理能力下降

#### 健康检查接口（网关自身接口）
- **性能特点**：
  - 吞吐量始终低于直接访问
  - **2000并发用户**时为 **8819 RPS**
  - **4000并发用户**时为 **4661 RPS**

- **性能下降原因**：
  - 网关自身接口需要处理额外逻辑（路由匹配、健康检查逻辑）
  - 网关服务与后端服务共享资源
  - 网关处理逻辑引入额外开销

### 5.2 无插件转发 vs 走插件转发

#### 无插件转发（网关仅做简单转发）
- **性能特点**：
  - 吞吐量随并发用户数增加略有波动
  - **1000并发用户**时为 **5525 RPS**
  - **1200并发用户**时为 **5389 RPS**

- **性能分析**：
  - 可能由于JMeter并发控制或系统资源波动导致结果不稳定
  - 整体吞吐量显著低于直接访问
  - 网关本身的处理逻辑（路由、负载均衡）引入性能损耗

#### 走插件转发（网关启用插件）
- **性能特点**：
  - 吞吐量显著低于无插件转发
  - **800并发用户**时仅为 **3460 RPS**
  - 远低于无插件转发的 **5525 RPS**（1000并发用户）

- **性能下降原因**：
  - 插件逻辑（请求头处理、灰度路由计算）增加额外处理开销
  - WASM插件的Golang实现可能引入约30微秒/请求的延迟
  - 在高并发场景下，微秒级延迟会显著降低吞吐量

### 5.3 性能瓶颈分析

#### 1. 硬件资源限制
- **测试机配置**：2核CPU + 2GB内存
- **部署复杂度**：网关、认证服务、两个Nginx实例共享资源
- **资源竞争**：4000并发用户时，资源可能完全耗尽
- **性能上限**：直接访问在2000并发用户时达到峰值

#### 2. 插件性能开销
- **插件逻辑复杂度**：请求头操作、灰度路由判断等
- **性能影响**：走插件转发吞吐量仅为无插件转发的63%
- **延迟分析**：自定义插件延迟约30微秒/请求
- **实际影响**：吞吐量下降幅度大于理论计算，可能与插件逻辑复杂度相关

#### 3. 网关自身开销
- **转发逻辑**：路由匹配、负载均衡等
- **性能损耗**：无插件转发吞吐量仅为直接访问的50%
- **优化空间**：网关本身的处理逻辑需要进一步优化